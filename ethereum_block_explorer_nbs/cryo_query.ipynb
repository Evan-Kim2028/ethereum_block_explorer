{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cryoQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp cryo_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# | export\n",
    "import jupyter_black\n",
    "import os\n",
    "import polars as pl\n",
    "import re\n",
    "import cryo\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "pl.Config.set_fmt_str_lengths(200)\n",
    "pl.Config.set_fmt_float(\"full\")\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/evan/Documents/ethereum_block_explorer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evan/Documents/ethereum_block_explorer/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@dataclass\n",
    "class cryoQuery:\n",
    "    \"\"\"\n",
    "    `cryoQuery` is used to query data from cryo\n",
    "    \"\"\"\n",
    "\n",
    "    raw_data_path: str = \"data/raw\"\n",
    "    rpc: str = \"https://eth.merkle.io\"\n",
    "\n",
    "    def _create_data_filepaths(self):\n",
    "        \"\"\"\n",
    "        Creates folders for storing raw data from cryo.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(self.raw_data_path):\n",
    "            os.makedirs(self.raw_data_path)\n",
    "            print(\"Data folder created.\")\n",
    "        else:\n",
    "            print(\"Data folder already exists.\")\n",
    "\n",
    "    def query_blocks_txs(\n",
    "        self,\n",
    "        n_error_threshold: int = 1,\n",
    "        retry_threshold: int = 5,\n",
    "        block_range: list[str] = [\"latest\"],\n",
    "        name: str = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Fetches block and transaction data. Attempts retries up to 'retry_threshold'. If errors exceed 'n_error_threshold'.\n",
    "\n",
    "        :param n_error_threshold: The number of allowed errors before retrying the query.\n",
    "        :param retry_threshold: The maximum number of retries for the query.\n",
    "        :param block_range: The range of blocks to query. Defaults to [\"latest\"].\n",
    "        \"\"\"\n",
    "        self._create_data_filepaths()\n",
    "        n_errored = n_error_threshold + 1\n",
    "        retry_count = 0\n",
    "\n",
    "        # make cryo query\n",
    "        while retry_count < retry_threshold:\n",
    "            print(f\"Retry count: {retry_count}\")\n",
    "            retry_count += 1\n",
    "            if n_error_threshold < n_errored:\n",
    "                output: dict[str] = cryo.freeze(\n",
    "                    \"blocks_and_transactions\",\n",
    "                    blocks=block_range,\n",
    "                    hex=True,\n",
    "                    rpc=self.rpc,\n",
    "                    no_verbose=False,  # this doesn't seem to have any effect\n",
    "                    output_dir=f\"data/raw_{name}\",\n",
    "                    subdirs=[\"datatype\"],\n",
    "                    include_columns=[\"n_rlp_bytes\"],\n",
    "                    exclude_columns=[\"input\", \"value\"],\n",
    "                    # compression=[\"zstd\"],\n",
    "                    compression=[\"lz4\"],  # bug, can't use zstd in cryo 0.3.0\n",
    "                )\n",
    "\n",
    "                n_errored = output[\"n_errored\"]\n",
    "                print(f\"Number of errors: {n_errored}\")\n",
    "            if n_errored == 0:\n",
    "                print(f\"{n_errored} == 0. Done!\")\n",
    "                break\n",
    "\n",
    "\n",
    "# | export\n",
    "@dataclass\n",
    "class cryoTransform:\n",
    "    \"\"\"\n",
    "    cryoTransform extends the underlying transactions and blocks dataset with extra columns.\n",
    "    \"\"\"\n",
    "\n",
    "    def extend_txs_blocks(\n",
    "        self,\n",
    "        txs: pl.LazyFrame,\n",
    "        blocks: pl.LazyFrame,\n",
    "        mempool: pl.LazyFrame | None = None,\n",
    "    ) -> pl.LazyFrame:\n",
    "        \"\"\"\n",
    "        Combines transaction, block, and optionally flashbots mempool data into a single LazyFrame.\n",
    "\n",
    "        Uses pattern matching to handle the optional mempool data.\n",
    "        If mempool data is provided, it is joined with the transactions and blocks data.\n",
    "        If not, only transactions and blocks are joined.\n",
    "\n",
    "        Preprocessing:\n",
    "        - add block percentile and ticks\n",
    "        - convert gas to gwei\n",
    "        - convert bytes to kilobytes\n",
    "\n",
    "\n",
    "        Parameters:\n",
    "        - txs (pl.LazyFrame): LazyFrame containing transaction data.\n",
    "        - blocks (pl.LazyFrame): LazyFrame containing block data.\n",
    "        - mempool (pl.LazyFrame, optional): LazyFrame containing mempool data. Default is None.\n",
    "\n",
    "        Returns:\n",
    "        - pl.LazyFrame: A unified LazyFrame with enriched transaction data.\n",
    "        \"\"\"\n",
    "\n",
    "        # Use pattern matching to handle the presence or absence of mempool data\n",
    "        match mempool:\n",
    "            case _ if isinstance(mempool, pl.LazyFrame):\n",
    "                # Join transactions with blocks and mempool data if mempool is provided\n",
    "                combined_df = txs.join(\n",
    "                    blocks, on=\"block_number\", how=\"left\", suffix=\"_block\"\n",
    "                ).join(\n",
    "                    mempool,\n",
    "                    right_on=\"hash\",\n",
    "                    left_on=\"transaction_hash\",\n",
    "                    how=\"left\",\n",
    "                    suffix=\"_mempool\",\n",
    "                )\n",
    "\n",
    "            case None:\n",
    "                # Join only transactions with blocks if mempool is not provided\n",
    "                combined_df = txs.join(\n",
    "                    blocks, on=\"block_number\", how=\"left\", suffix=\"_block\"\n",
    "                )\n",
    "\n",
    "        agg_df: pl.LazyFrame = combined_df.group_by(\"block_number\").agg(\n",
    "            [\n",
    "                pl.col(\"transaction_index\").max().alias(\n",
    "                    \"transaction_index_max\"),\n",
    "                pl.col(\"n_rlp_bytes\").sum().alias(\"block_encoded_bytes\"),\n",
    "                pl.col(\"n_input_bytes\").sum().alias(\"block_calldata_bytes\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            combined_df.join(agg_df, on=\"block_number\", how=\"left\")\n",
    "            .with_columns(\n",
    "                [\n",
    "                    # Calculate the transaction gas cost\n",
    "                    (pl.col(\"gas_used\") * pl.col(\"gas_price\") / 10**18).alias(\n",
    "                        \"tx_gas_cost\"\n",
    "                    ),\n",
    "                    # Convert epoch timestamp to datetime\n",
    "                    pl.from_epoch(\"timestamp\").alias(\"block_datetime\"),\n",
    "                    # Calculate the gas price premium over the base fee per gas\n",
    "                    (pl.col(\"gas_price\") / pl.col(\"base_fee_per_gas\")).alias(\n",
    "                        \"block_gas_premium\"\n",
    "                    ),\n",
    "                    (pl.col(\"base_fee_per_gas\").rolling_mean(window_size=7200)).alias(\n",
    "                        \"avg_base_fee_daily\"\n",
    "                    ),\n",
    "                    (pl.col(\"base_fee_per_gas\").rolling_mean(window_size=300)).alias(\n",
    "                        \"avg_base_fee_hourly\"\n",
    "                    ),\n",
    "                    (pl.col(\"base_fee_per_gas\").rolling_mean(window_size=5)).alias(\n",
    "                        \"avg_base_fee_minute\"\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "            .with_columns(\n",
    "                # Calculate the transaction index percentile within its block\n",
    "                (\n",
    "                    pl.col(\"transaction_index\") / \\\n",
    "                    pl.col(\"transaction_index_max\") * 100\n",
    "                ).alias(\"blockspace_percentile\")\n",
    "            )\n",
    "            .with_columns(\n",
    "                # Round the block space percentile for easier interpretation\n",
    "                (pl.col(\"blockspace_percentile\").round()).alias(\n",
    "                    \"rounded_blockspace_percentile\"\n",
    "                )\n",
    "            )\n",
    "            # unit conversions\n",
    "            .with_columns(\n",
    "                # convert gas to gwei\n",
    "                (pl.col(\"gas_price\") / 10**9).alias(\"gas_price_gwei\"),\n",
    "                (pl.col(\"max_priority_fee_per_gas\") / 10**9).alias(\n",
    "                    \"max_priority_fee_per_gas_gwei\"\n",
    "                ),\n",
    "                (pl.col(\"max_fee_per_gas\") / 10**9).alias(\"max_fee_per_gas_gwei\"),\n",
    "                (pl.col(\"base_fee_per_gas\") / 10 **\n",
    "                 9).alias(\"base_fee_per_gas_gwei\"),\n",
    "                (pl.col(\"avg_base_fee_daily\") / 10**9).alias(\n",
    "                    \"avg_base_fee_daily_gwei\"\n",
    "                ),\n",
    "                (pl.col(\"avg_base_fee_hourly\") / 10**9).alias(\n",
    "                    \"avg_base_fee_hourly_gwei\"\n",
    "                ),\n",
    "                (pl.col(\"avg_base_fee_minute\") / 10**9).alias(\n",
    "                    \"avg_base_fee_minute_gwei\"\n",
    "                ),\n",
    "                # convert bytes to kilobytes\n",
    "                (pl.col(\"block_encoded_bytes\") / 10 **\n",
    "                 3).alias(\"block_encoded_kbytes\"),\n",
    "                (pl.col(\"block_calldata_bytes\") / 10**3).alias(\n",
    "                    \"block_calldata_kbytes\"\n",
    "                ),\n",
    "            )\n",
    "            .drop(\n",
    "                \"gas_price\",\n",
    "                \"max_priority_fee_per_gas\",\n",
    "                \"max_fee_per_gas\",\n",
    "                \"base_fee_per_gas\",\n",
    "                \"block_encoded_bytes\",\n",
    "                \"block_calldata_bytes\",\n",
    "            )\n",
    "            .fill_nan(0)  # Fill NaN values with 0\n",
    "            .unique()  # Ensure all rows are unique\n",
    "        )\n",
    "\n",
    "    # 1. read the files in the raw data from block number partitions, sync them together, perform a transformation, and then save into a new folder.\n",
    "    def read_filenames(self, directory) -> list:\n",
    "        try:\n",
    "            return sorted(\n",
    "                [\n",
    "                    f\n",
    "                    for f in os.listdir(directory)\n",
    "                    if os.path.isfile(os.path.join(directory, f))\n",
    "                ]\n",
    "            )\n",
    "        except FileNotFoundError:\n",
    "            return []\n",
    "\n",
    "    def extract_block_batch_index(self, filename) -> list[tuple]:\n",
    "        match = re.search(r\"to_(\\d+)\", filename)\n",
    "        return int(match.group(1)) if match else None\n",
    "\n",
    "    def sync_filenames(self, directory_a: str, directory_b: str):\n",
    "        # Read filenames from both directories\n",
    "        transactions_filenames = self.read_filenames(directory_a)\n",
    "        blocks_filenames = self.read_filenames(directory_b)\n",
    "\n",
    "        # Extract numbers and create mappings\n",
    "        transactions_mapping = {\n",
    "            self.extract_block_batch_index(name): name\n",
    "            for name in transactions_filenames\n",
    "        }\n",
    "        blocks_mapping = {\n",
    "            self.extract_block_batch_index(name): name for name in blocks_filenames\n",
    "        }\n",
    "\n",
    "        # Find common keys\n",
    "        common_keys = set(transactions_mapping.keys()).intersection(\n",
    "            blocks_mapping.keys()\n",
    "        )\n",
    "\n",
    "        # Creating synced files dictionary\n",
    "        synced_files = {\n",
    "            directory_a: [transactions_mapping[key] for key in common_keys],\n",
    "            directory_b: [blocks_mapping[key] for key in common_keys],\n",
    "        }\n",
    "\n",
    "        return synced_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data folder already exists.\n",
      "Retry count: 0\n",
      "\u001b[1;37mcryo parameters\u001b[0m\n",
      "\u001b[38;2;0;225;0m───────────────\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mversion\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m0.3.2\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mdata\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mdatatypes\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mblocks, transactions\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblocks\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mn=100,000 min=174,061,989 max=174,161,988 align=no reorg_buffer=0\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37msource\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mnetwork\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170marbitrum\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mrpc url\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhttps://rpc.merkle.io/42161/sk_mbs_52643548f289817e03f67d550224141c\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mmax requests per second\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170munlimited\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mmax concurrent requests\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170munlimited\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mmax concurrent chunks\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m4\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37moutput\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mchunk size\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m1,000\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mchunks to collect\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m100 / 100\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37moutput format\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mparquet\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37moutput dir\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m/home/evan/Documents/ethereum_block_explorer/data/raw\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mreport file\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m$OUTPUT_DIR/.cryo/reports/2024-01-25_17-08-53.350060.json\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;37mschema for blocks\u001b[0m\n",
      "\u001b[38;2;0;225;0m─────────────────\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblock_number\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblock_hash\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mtimestamp\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mauthor\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mgas_used\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mextra_data\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mbase_fee_per_gas\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mchain_id\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\n",
      "sorting blocks by: block_number\n",
      "\n",
      "other available columns: parent_hash, state_root, transactions_root, receipts_root, logs_bloom, total_difficulty, size\n",
      "\n",
      "\n",
      "\u001b[1;37mschema for transactions\u001b[0m\n",
      "\u001b[38;2;0;225;0m───────────────────────\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblock_number\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mtransaction_index\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mtransaction_hash\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mnonce\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mfrom_address\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mto_address\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mhex\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mgas_limit\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mgas_used\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mgas_price\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mtransaction_type\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mmax_priority_fee_per_gas\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mmax_fee_per_gas\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37msuccess\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170mbool\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mn_input_bytes\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mn_input_zero_bytes\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mn_input_nonzero_bytes\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mchain_id\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint64\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mn_rlp_bytes\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170muint32\u001b[0m\n",
      "\n",
      "sorting transactions by: block_number, transaction_index\n",
      "\n",
      "other available columns: value, input, block_hash, timestamp\n",
      "\n",
      "\n",
      "\u001b[1;37mcollecting data\u001b[0m\n",
      "\u001b[38;2;0;225;0m───────────────\u001b[0m\n",
      "started at 2024-01-25 17:08:53.350\n",
      "   done at 2024-01-25 17:21:14.445\n",
      "\n",
      "\n",
      "\u001b[1;37merror summary\u001b[0m\n",
      "\u001b[38;2;225;0;0m─────────────\u001b[0m\n",
      "(errors in 1 chunks)\n",
      "- Failed to get block: error sending request for url (https://rpc.merkle.io/42161/sk_mbs_52643548f289817e03f67d550224141c): connection error: connection reset (1x)\n",
      "\n",
      "\n",
      "\u001b[1;37mcollection summary\u001b[0m\n",
      "\u001b[38;2;0;225;0m──────────────────\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mtotal duration\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m741.095 seconds\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mtotal chunks\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m100\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mchunks errored\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m    1 / 100 (1.0%)\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mchunks skipped\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m    0 / 100 (0.0%)\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mchunks collected\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m 99 / 100 (99.0%)\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblocks collected\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m99,000\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblocks per second\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m    133.6\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblocks per minute\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m  8,015.2\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblocks per hour\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m  480,909.4\u001b[0m\n",
      "    \u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mblocks per day\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m11,541,826.2\u001b[0m\n",
      "\u001b[38;2;0;225;0m- \u001b[0m\u001b[1;37mrows written\u001b[0m\u001b[38;2;0;225;0m: \u001b[0m\u001b[38;2;170;170;170m443,645\u001b[0m\n",
      "Number of errors: 1\n",
      "Retry count: 1\n",
      "Retry count: 2\n",
      "Retry count: 3\n",
      "Retry count: 4\n"
     ]
    }
   ],
   "source": [
    "# sample usage\n",
    "cryo_query = cryoQuery(\n",
    "    rpc=\"https://rpc.merkle.io/42161/sk_mbs_52643548f289817e03f67d550224141c\"\n",
    ")\n",
    "\n",
    "cryo_query.query_blocks_txs(block_range=[\"174061989:174161989\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.read_parquet(\"data/raw/blocks/*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>block_hash</th><th>author</th><th>block_number</th><th>gas_used</th><th>extra_data</th><th>timestamp</th><th>base_fee_per_gas</th><th>chain_id</th></tr><tr><td>str</td><td>str</td><td>u32</td><td>u64</td><td>str</td><td>u32</td><td>u64</td><td>u64</td></tr></thead><tbody><tr><td>&quot;0xbc8ec21c3ef5714908b083bf8f415e77e3036ed3f4e8823c0095d4f038260612&quot;</td><td>&quot;0xa4b000000000000000000073657175656e636572&quot;</td><td>174161989</td><td>1900624</td><td>&quot;0x570571e8c3aac708dd897a3d64a118c3daf365c88bbc5669ed27ad8f5609d476&quot;</td><td>1706218447</td><td>100000000</td><td>42161</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 8)\n",
       "┌────────────┬────────────┬────────────┬──────────┬────────────┬────────────┬───────────┬──────────┐\n",
       "│ block_hash ┆ author     ┆ block_numb ┆ gas_used ┆ extra_data ┆ timestamp  ┆ base_fee_ ┆ chain_id │\n",
       "│ ---        ┆ ---        ┆ er         ┆ ---      ┆ ---        ┆ ---        ┆ per_gas   ┆ ---      │\n",
       "│ str        ┆ str        ┆ ---        ┆ u64      ┆ str        ┆ u32        ┆ ---       ┆ u64      │\n",
       "│            ┆            ┆ u32        ┆          ┆            ┆            ┆ u64       ┆          │\n",
       "╞════════════╪════════════╪════════════╪══════════╪════════════╪════════════╪═══════════╪══════════╡\n",
       "│ 0xbc8ec21c ┆ 0xa4b00000 ┆ 174161989  ┆ 1900624  ┆ 0x570571e8 ┆ 1706218447 ┆ 100000000 ┆ 42161    │\n",
       "│ 3ef5714908 ┆ 0000000000 ┆            ┆          ┆ c3aac708dd ┆            ┆           ┆          │\n",
       "│ b083bf8f41 ┆ 0000736571 ┆            ┆          ┆ 897a3d64a1 ┆            ┆           ┆          │\n",
       "│ 5e77e3036e ┆ 75656e6365 ┆            ┆          ┆ 18c3daf365 ┆            ┆           ┆          │\n",
       "│ d3f4e8823c ┆ 72         ┆            ┆          ┆ c88bbc5669 ┆            ┆           ┆          │\n",
       "│ 0095d4f038 ┆            ┆            ┆          ┆ ed27ad8f56 ┆            ┆           ┆          │\n",
       "│ 260612     ┆            ┆            ┆          ┆ 09d476     ┆            ┆           ┆          │\n",
       "└────────────┴────────────┴────────────┴──────────┴────────────┴────────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
